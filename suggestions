Luku 2.2: Voisi olla hieman laajempi, erityisesti selittää konvoluution periaatteen
tarkemmin ja perustella mistä edut tulevat. Kuvan 2 selitystä voisi parantaa hieman
ja lisäksi voisi ehkä olla jokin kuva syvemmästä verkosta.

Luku 2.3: Aluksi on varmaan hyvä selittää, mitä autoencoder ja stacked autoencoder
ovat. Lisää laajuutta tai yhdistys muihin lukuihin (joko luvussa 2 tai sitten tarpeen
tullen trackereita esitellessä). Ei ehkä ole tarpeen selittää autoenkoodereita kovin
tarkasti.

Luku 3: Alussa on hyvä määritellä kohteenseuranta, kuvaesimerkkien kanssa.

Luku 3.1: Hyvä pohja. Vielä selkeytystä ja hieman lähteitä. Voi laittaa myös viittauksia
review-artikkeleihin, jotka ovat vertailleet useita perinteisiä menetelmiä.


Luku 3.2: Voi korostaa, että esittelyssä on nyt kahdenlaisia aineistoja, 1) kuva- ja
videoaineistot kuvapiirteiden ja luokittelun oppimiseen ja 2) varsinaiset tracking-
aineistot, ja selittää miksi molemmat voivat olla hyödyllisiä kohteenseurannassa. Sen
ILSVRC:n "object detection from video" osalta en muista tarkasti, mutta saattoi olla,
että siinä ei ole annotaatioita (bounding boxeja) seurattavalle kohteelle. Ainakin
perinteisesti ILSVRC:n videoaineistoissa taisi olla ajatuksena, että osataan paremmin
sanoa, onko kuvassa kissa vai koira, kun on saatu oppiessa enemmän aineistoa (sama kohde
hieman muuttuvana videossa). Videon kuvia käsiteltiin ihan yksittäisinä.

Luku 3.3: Hieman laajemmaksi.